{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tika\n",
    "from tika import parser\n",
    "import nltk.data\n",
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/french.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tika\n",
      "  Using cached tika-1.24.tar.gz (28 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marco\\anaconda3\\lib\\site-packages (from tika) (49.2.0.post20200714)\n",
      "Requirement already satisfied: requests in c:\\users\\marco\\anaconda3\\lib\\site-packages (from tika) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->tika) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->tika) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->tika) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\marco\\anaconda3\\lib\\site-packages (from requests->tika) (1.25.9)\n",
      "Building wheels for collected packages: tika\n",
      "  Building wheel for tika (setup.py): started\n",
      "  Building wheel for tika (setup.py): finished with status 'done'\n",
      "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32888 sha256=8cb9d4e6123005bbe6c0e1b4b42d4fcbb5354967c495d281faeddd781ace9ed8\n",
      "  Stored in directory: c:\\users\\marco\\appdata\\local\\pip\\cache\\wheels\\75\\66\\8b\\d1acbac7d49f3d98ade76c51ae5d72cec1866131a3b1ad9f82\n",
      "Successfully built tika\n",
      "Installing collected packages: tika\n",
      "Successfully installed tika-1.24\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tika\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_extractor(path,file):\n",
    "    \"\"\"\n",
    "    Extract text from a given PDF or a Word documents and returns a dataframe where each sentences is a new row \n",
    "    of the returned dataframe.\n",
    "    INPUT: -path (string): path that contain the wanted document.\n",
    "           -name (string): name of the csv document to be used for predictions.\n",
    "    OUTPUT: - df(dataframe): dataframe containing all the sentences of the text\n",
    "    \"\"\"\n",
    "    # Remove .pdf from the filename so we can use it as the name of the plot and PNG\n",
    "    if file.endswith(\".pdf\"):\n",
    "        filename = file.strip('.pdf')\n",
    "    if file.endswith(\".docx\"):\n",
    "        filename = file.strip('.docx')\n",
    "    # Parse data from file\n",
    "    file_data = parser.from_file(os.path.join(path,file))\n",
    "    text = file_data['content']\n",
    "    text = text.splitlines()\n",
    "    text = [\" \".join(b.split()) for b in text]\n",
    "    text = [t for t in text if \".....\" not in t]\n",
    "    listToStr = ' '.join(map(str, text))\n",
    "    listToStr = listToStr.replace(\"â€™\", \"'\")\n",
    "    listToStr = listToStr.replace(\"-\",' ')\n",
    "    data = (tokenizer.tokenize(listToStr))\n",
    "    new_data = []\n",
    "    for i in range(int(len(data)/2)):\n",
    "        j = 2*i\n",
    "        new_data.append(data[j] + \" \" + data[j+1])\n",
    "    df = pd.DataFrame(new_data)\n",
    "    df = df.rename(columns={0:\"Kept sentences\"})\n",
    "    df.to_csv(\"Table_{}.csv\".format(filename))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Step 1: Insert Path Name : C:\\Users\\marco\\Desktop\\Desktop\\Sacha\\\n",
      "Step 2: Insert File Name : year-end-presentation-2019.pdf\n"
     ]
    }
   ],
   "source": [
    "path = input(\"Step 1: Insert Path Name :\")\n",
    "file = input(\"Step 2: Insert File Name :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kept sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The forward looking  statements in this presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kingspan undertakes no duty to and will not ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 The thermal conductivity range is based on d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13% better1  89% better1  Conversion Growth   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Steps now  taken to ensure competitiveness is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&gt; Significant progress across Americas  &gt; Pene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Production to commence mid 2021  26  2019 2018...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Kept sentences\n",
       "0                                                ...\n",
       "1  The forward looking  statements in this presen...\n",
       "2  Kingspan undertakes no duty to and will not ne...\n",
       "3  2 The thermal conductivity range is based on d...\n",
       "4  13% better1  89% better1  Conversion Growth   ...\n",
       "5  Steps now  taken to ensure competitiveness is ...\n",
       "6  > Significant progress across Americas  > Pene...\n",
       "7  Production to commence mid 2021  26  2019 2018..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_extractor(path,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
