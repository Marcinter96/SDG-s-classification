{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Desktop\\Python\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#NLP libraries\n",
    "import sklearn\n",
    "# sklearn packages\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_curve\n",
    "from sklearn.metrics import auc,f1_score,roc_auc_score,precision_recall_curve,precision_score\n",
    "# xgboost packages\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# nltk packages\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Desktop\\Python\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Getting all the required file for cleaning and predictions\n",
    "rep_file = \"Input/df_replacement.csv\"\n",
    "channel_file = \"Input/Channel_selected.csv\"\n",
    "stop_file = \"Input/df_stopwords.csv\"\n",
    "# Getting the wanted word for dictionary\n",
    "replacement = pd.read_csv(rep_file, encoding ='latin-1' )\n",
    "channel = pd.read_csv(channel_file, encoding ='latin-1' )\n",
    "stopwords_list = pd.read_csv(stop_file, encoding ='latin-1' ).drop(\"type\", axis = 1)\n",
    "frames = [replacement, channel]\n",
    "result = pd.concat(frames)\n",
    "result = result.dropna()\n",
    "dico = dict(zip(result.old, result.new))\n",
    "stop_words1 =  stopwords.words('english') + list(stopwords_list[\"stopwords\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lemmatizer + tokenizer (+ stemming) class\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        # we define (but not use) a stemming method, uncomment the last line in __call__ to get stemming tooo\n",
    "        self.stemmer = nltk.stem.SnowballStemmer('english') \n",
    "    def __call__(self, doc):\n",
    "        # pattern for numbers | words of length=2 | punctuations | words of length=1\n",
    "        pattern = re.compile(r'[0-9]+|\\b[\\w]{2,2}\\b|[%.,_`!\"&?\\')({~@;:#}+-]+|\\b[\\w]{1,1}\\b')\n",
    "        # tokenize document\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        #filter out patterns from words\n",
    "        doc_tok = [x for x in doc_tok if x not in stop_words1]\n",
    "        doc_tok = [pattern.sub('', x) for x in doc_tok]\n",
    "        # get rid of anything with length=1\n",
    "        doc_tok = [x for x in doc_tok if len(x) > 2]\n",
    "        doc = [self.wnl.lemmatize(t) for t in doc_tok]\n",
    "        # uncomment if you want stemming as well\n",
    "        doc = [self.stemmer.stem(x) for x in doc]\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_new_replace(s, dico):\n",
    "    \"\"\"\n",
    "   Replaces word in a string to the new wanted word in the dictionary\n",
    "    INPUT: -s (string): string we want to modify the given word\n",
    "           -dico (dict): list of word and their replace new word.\n",
    "    OUTPUT: - (string): \n",
    "    \"\"\"\n",
    "    new_s = s\n",
    "    for old, new in dico.items():\n",
    "        new_s = new_s.replace(old, new)\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the final trainset, \n",
    "train_file = \"Input/trainset.csv\"\n",
    "\n",
    "train = pd.read_csv(train_file, encoding = \"latin-1\")\n",
    "train[\"new text\"] = train[\"Description\"].apply(lambda x: old_new_replace(x,dico))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer instantiation with stop words, setting to count words of 1-grams and do not filter words based on their frequency\n",
    "count_vec = CountVectorizer(lowercase=True,min_df=1,analyzer='word',tokenizer = LemmaTokenizer(), ngram_range=(1,2))#tokenizer = LemmaTokenizer()\n",
    "vect_word = TfidfVectorizer(lowercase=True,min_df=1,analyzer='word',tokenizer = LemmaTokenizer(),ngram_range=(1,2))#tokenizer = LemmaTokenizer()\n",
    "fit = train[\"new text\"]\n",
    "feat = vect_word.fit_transform(fit.values)\n",
    "feat_name = vect_word.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split(train, target_col = [\"SDG{}\".format(i) for i in range(1,18)]):\n",
    "    \"\"\"\n",
    "    Perform train test split on given data-set\n",
    "    INPUT: -train (dataframe): Training data we want to split\n",
    "           -target_col(list): Columns name that we want to predict results.\n",
    "    OUTPUT:  -  (dataframe): splitting of dataframe to validate model.\n",
    "    \"\"\"\n",
    "    train_pdf = train[:15798]\n",
    "    train_crs = train[15798:]\n",
    "    train_crs = train_crs.sample(frac=1)\n",
    "    N = len(train_crs)\n",
    "    X_train_crs = train_crs[\"new text\"][0:int(N*0.9)]\n",
    "    y_train_crs = train_crs[target_col][0:int(N*0.9)]\n",
    "    X_test = train_crs[\"new text\"][int(N*0.9):]\n",
    "    y_test = train_crs[target_col][int(N*0.9):]\n",
    "    X_train_pdf = train_pdf[\"new text\"]\n",
    "    y_train_pdf = train_pdf[target_col]\n",
    "    frames_X = [X_train_pdf,X_train_crs]\n",
    "    frames_y = [y_train_pdf,y_train_crs]\n",
    "    X_train = pd.concat(frames_X)\n",
    "    y_train = pd.concat(frames_y)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tres(precision, recall, threshold,col):\n",
    "    \"\"\"\n",
    "    Find the best treshold that maximizes the F1-score for class 1\n",
    "    \"\"\"    \n",
    "    thres = list(threshold)\n",
    "    thres.append(1)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    F1 = list(F1)\n",
    "    ind = F1.index(max(F1))\n",
    "    if thres[ind]< 0.1:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return round(thres[ind],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_prediction_xgb(train,target_col = [\"SDG{}\".format(i) for i in range(1,18)]):\n",
    "    \"\"\"\n",
    "    Perform 17 binary logistic predictions to see if each entries is in one or many classes.\n",
    "    INPUT: -train (dataframe): Training data we want to split\n",
    "           -target_col(list): Columns name that we want to predict results.\n",
    "    OUTPUT:  -  fits(joblib): Export the fits as a joblib file\n",
    "                treshold(dataframe): Export the chosen treshold as a csv file\n",
    "    \"\"\"\n",
    "    eta_par = 0.1\n",
    "    #max_step = 1\n",
    "    nrounds_par = 5 / eta_par\n",
    "    X_train,X_test,y_train,y_test = split(train)\n",
    "    mat = vect_word.transform(X_train.values)\n",
    "    mat_test = vect_word.transform(X_test.values)\n",
    "    prd = pd.DataFrame()\n",
    "    prd_proba = pd.DataFrame()\n",
    "    prd[\"Index\"] = X_test.index.values\n",
    "    prd_proba['Index'] = X_test.index.values\n",
    "    treshold = []\n",
    "    cv_score = []\n",
    "    for i,col in enumerate(target_col):\n",
    "        # parameters to be tries in the grid search\n",
    "        #cv_params = {'eta':[0.1,0.2,0.3]}  \n",
    "        if i in [16]:\n",
    "            eta_par = 0.2\n",
    "            max_step = 2\n",
    "        fix_params = {'random_state':42, 'seed':2, 'max_depth':17, 'verbosity':1,'eta': eta_par,\n",
    "                    'nrounds':nrounds_par, 'objective':\"binary:logistic\",\"max_delta_step\" :0}\n",
    "        \n",
    "        clf = XGBClassifier(**fix_params)\n",
    "        clf.fit(mat, y_train[col])\n",
    "        #clf_test.fit(mat,y_train[col])\n",
    "        prd_proba[col] = clf.predict_proba(mat_test)[:,1]\n",
    "        joblib.dump(clf,open('Saved_Fit/Model_Fit_{}.joblib'.format(col), \"wb\"))\n",
    "        model_probs = clf.predict_proba(mat_test)[:,1]\n",
    "        # calculate roc auc\n",
    "        roc_auc = roc_auc_score(y_test[col], model_probs,)\n",
    "        print('XGBoost ROC AUC %.3f' % roc_auc)\n",
    "        # calculate the precision-recall auc\n",
    "        precision, recall, threshold = precision_recall_curve(y_test[col], model_probs)\n",
    "        tres = get_tres(precision, recall, threshold,col)\n",
    "        auc_score = auc(recall, precision)\n",
    "        print('XGBoost PR AUC: %.3f' % auc_score)\n",
    "        prd[col] = 0\n",
    "        for j in range(len(prd_proba[col])):\n",
    "            if prd_proba[col][j] > tres:\n",
    "                prd[col][j]  = 1\n",
    "            else:\n",
    "                prd[col][j] = 0\n",
    "        cv_score.append(metrics.accuracy_score(y_test[col],prd[col]))\n",
    "        print(cv_score)\n",
    "        print('\\nConfusion matrix\\n',confusion_matrix(y_test[col],prd[col]))\n",
    "        print(classification_report(y_test[col],prd[col]))\n",
    "        treshold.append(tres)\n",
    "    treshold_frame = pd.DataFrame(treshold).rename(columns={0:\"Tresholds\"})\n",
    "    treshold_frame.to_csv(\"Saved_Fit/Treshold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ROC AUC 0.950\n",
      "XGBoost PR AUC: 0.752\n",
      "[0.9824561403508771]\n",
      "\n",
      "Confusion matrix\n",
      " [[656   2]\n",
      " [ 10  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       658\n",
      "           1       0.89      0.62      0.73        26\n",
      "\n",
      "    accuracy                           0.98       684\n",
      "   macro avg       0.94      0.81      0.86       684\n",
      "weighted avg       0.98      0.98      0.98       684\n",
      "\n",
      "XGBoost ROC AUC 0.943\n",
      "XGBoost PR AUC: 0.818\n",
      "[0.9824561403508771, 0.9576023391812866]\n",
      "\n",
      "Confusion matrix\n",
      " [[600   9]\n",
      " [ 20  55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       609\n",
      "           1       0.86      0.73      0.79        75\n",
      "\n",
      "    accuracy                           0.96       684\n",
      "   macro avg       0.91      0.86      0.88       684\n",
      "weighted avg       0.96      0.96      0.96       684\n",
      "\n",
      "XGBoost ROC AUC 0.964\n",
      "XGBoost PR AUC: 0.887\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251]\n",
      "\n",
      "Confusion matrix\n",
      " [[568  24]\n",
      " [ 11  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       592\n",
      "           1       0.77      0.88      0.82        92\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.88      0.92      0.90       684\n",
      "weighted avg       0.95      0.95      0.95       684\n",
      "\n",
      "XGBoost ROC AUC 0.964\n",
      "XGBoost PR AUC: 0.824\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315]\n",
      "\n",
      "Confusion matrix\n",
      " [[586  21]\n",
      " [ 15  62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       607\n",
      "           1       0.75      0.81      0.77        77\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.86      0.89      0.87       684\n",
      "weighted avg       0.95      0.95      0.95       684\n",
      "\n",
      "XGBoost ROC AUC 0.990\n",
      "XGBoost PR AUC: 0.931\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707]\n",
      "\n",
      "Confusion matrix\n",
      " [[633   3]\n",
      " [  8  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       636\n",
      "           1       0.93      0.83      0.88        48\n",
      "\n",
      "    accuracy                           0.98       684\n",
      "   macro avg       0.96      0.91      0.94       684\n",
      "weighted avg       0.98      0.98      0.98       684\n",
      "\n",
      "XGBoost ROC AUC 0.972\n",
      "XGBoost PR AUC: 0.928\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707]\n",
      "\n",
      "Confusion matrix\n",
      " [[634   7]\n",
      " [  4  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       641\n",
      "           1       0.85      0.91      0.88        43\n",
      "\n",
      "    accuracy                           0.98       684\n",
      "   macro avg       0.92      0.95      0.93       684\n",
      "weighted avg       0.98      0.98      0.98       684\n",
      "\n",
      "XGBoost ROC AUC 0.988\n",
      "XGBoost PR AUC: 0.814\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579]\n",
      "\n",
      "Confusion matrix\n",
      " [[645   4]\n",
      " [  5  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       649\n",
      "           1       0.88      0.86      0.87        35\n",
      "\n",
      "    accuracy                           0.99       684\n",
      "   macro avg       0.94      0.93      0.93       684\n",
      "weighted avg       0.99      0.99      0.99       684\n",
      "\n",
      "XGBoost ROC AUC 0.942\n",
      "XGBoost PR AUC: 0.764\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866]\n",
      "\n",
      "Confusion matrix\n",
      " [[616  10]\n",
      " [ 19  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       626\n",
      "           1       0.80      0.67      0.73        58\n",
      "\n",
      "    accuracy                           0.96       684\n",
      "   macro avg       0.88      0.83      0.85       684\n",
      "weighted avg       0.96      0.96      0.96       684\n",
      "\n",
      "XGBoost ROC AUC 0.950\n",
      "XGBoost PR AUC: 0.833\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315]\n",
      "\n",
      "Confusion matrix\n",
      " [[595  17]\n",
      " [ 19  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       612\n",
      "           1       0.76      0.74      0.75        72\n",
      "\n",
      "    accuracy                           0.95       684\n",
      "   macro avg       0.86      0.85      0.86       684\n",
      "weighted avg       0.95      0.95      0.95       684\n",
      "\n",
      "XGBoost ROC AUC 0.904\n",
      "XGBoost PR AUC: 0.630\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801]\n",
      "\n",
      "Confusion matrix\n",
      " [[631   9]\n",
      " [ 19  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       640\n",
      "           1       0.74      0.57      0.64        44\n",
      "\n",
      "    accuracy                           0.96       684\n",
      "   macro avg       0.85      0.78      0.81       684\n",
      "weighted avg       0.96      0.96      0.96       684\n",
      "\n",
      "XGBoost ROC AUC 0.901\n",
      "XGBoost PR AUC: 0.508\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883]\n",
      "\n",
      "Confusion matrix\n",
      " [[611  19]\n",
      " [ 25  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       630\n",
      "           1       0.60      0.54      0.57        54\n",
      "\n",
      "    accuracy                           0.94       684\n",
      "   macro avg       0.78      0.75      0.77       684\n",
      "weighted avg       0.93      0.94      0.93       684\n",
      "\n",
      "XGBoost ROC AUC 0.910\n",
      "XGBoost PR AUC: 0.635\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883, 0.9839181286549707]\n",
      "\n",
      "Confusion matrix\n",
      " [[661   4]\n",
      " [  7  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       665\n",
      "           1       0.75      0.63      0.69        19\n",
      "\n",
      "    accuracy                           0.98       684\n",
      "   macro avg       0.87      0.81      0.84       684\n",
      "weighted avg       0.98      0.98      0.98       684\n",
      "\n",
      "XGBoost ROC AUC 0.935\n",
      "XGBoost PR AUC: 0.715\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883, 0.9839181286549707, 0.9692982456140351]\n",
      "\n",
      "Confusion matrix\n",
      " [[627   7]\n",
      " [ 14  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       634\n",
      "           1       0.84      0.72      0.77        50\n",
      "\n",
      "    accuracy                           0.97       684\n",
      "   macro avg       0.91      0.85      0.88       684\n",
      "weighted avg       0.97      0.97      0.97       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Desktop\\Python\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ROC AUC 0.995\n",
      "XGBoost PR AUC: 0.913\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883, 0.9839181286549707, 0.9692982456140351, 0.9926900584795322]\n",
      "\n",
      "Confusion matrix\n",
      " [[666   2]\n",
      " [  3  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       668\n",
      "           1       0.87      0.81      0.84        16\n",
      "\n",
      "    accuracy                           0.99       684\n",
      "   macro avg       0.93      0.90      0.92       684\n",
      "weighted avg       0.99      0.99      0.99       684\n",
      "\n",
      "XGBoost ROC AUC 0.997\n",
      "XGBoost PR AUC: 0.940\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883, 0.9839181286549707, 0.9692982456140351, 0.9926900584795322, 0.9912280701754386]\n",
      "\n",
      "Confusion matrix\n",
      " [[651   2]\n",
      " [  4  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       653\n",
      "           1       0.93      0.87      0.90        31\n",
      "\n",
      "    accuracy                           0.99       684\n",
      "   macro avg       0.96      0.93      0.95       684\n",
      "weighted avg       0.99      0.99      0.99       684\n",
      "\n",
      "XGBoost ROC AUC 0.938\n",
      "XGBoost PR AUC: 0.812\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883, 0.9839181286549707, 0.9692982456140351, 0.9926900584795322, 0.9912280701754386, 0.9122807017543859]\n",
      "\n",
      "Confusion matrix\n",
      " [[542  32]\n",
      " [ 28  82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       574\n",
      "           1       0.72      0.75      0.73       110\n",
      "\n",
      "    accuracy                           0.91       684\n",
      "   macro avg       0.84      0.84      0.84       684\n",
      "weighted avg       0.91      0.91      0.91       684\n",
      "\n",
      "XGBoost ROC AUC 0.892\n",
      "XGBoost PR AUC: 0.644\n",
      "[0.9824561403508771, 0.9576023391812866, 0.9488304093567251, 0.9473684210526315, 0.9839181286549707, 0.9839181286549707, 0.9868421052631579, 0.9576023391812866, 0.9473684210526315, 0.9590643274853801, 0.935672514619883, 0.9839181286549707, 0.9692982456140351, 0.9926900584795322, 0.9912280701754386, 0.9122807017543859, 0.9239766081871345]\n",
      "\n",
      "Confusion matrix\n",
      " [[595  16]\n",
      " [ 36  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       611\n",
      "           1       0.70      0.51      0.59        73\n",
      "\n",
      "    accuracy                           0.92       684\n",
      "   macro avg       0.82      0.74      0.77       684\n",
      "weighted avg       0.92      0.92      0.92       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "separate_prediction_xgb(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
